{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import whisper\n",
    "import os.path as osp\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 처리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __data_process 함수__ \n",
    ">\n",
    "> aihub의 [소음 환경 음성인식 데이터](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=568)를 처리하는 함수로, 다른 데이터는 텍스트 처리가 달라질 수 있습니다.\n",
    ">\n",
    "> 경로를 입력으로 받아 웨이브폼과 텍스트로 각각 처리합니다.\n",
    "> \n",
    "> 발화자가 바뀔 때를 기준으로 오디오를 잘라 리스트 형태로 반환합니다. (audio_arr, text_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 텍스트 전처리(preprocess 함수)의 경우 https://github.com/sooftware/ksponspeech 를 참조하였습니다. 위스퍼도 숫자를 포함한 추론 결과를 내기 때문에 아래 코드에서는 option2를 선택하였습니다. \n",
    ">   \n",
    "> - Option1 : phonetic transcript     \n",
    "> ``칠 십 퍼센트 확률이라니 아 모 몬 소리야 진짜 백 프로가 왜 안돼?``       \n",
    "> - Option2 : spelling transcript     \n",
    "> ``70% 확률이라니 아 뭐 뭔 소리야 진짜 100%가 왜 안돼?``       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이 코드 블록은 ksponspeech/preprocess/preprocess.py에서 복사해온 코드입니다. \n",
    "import os\n",
    "import re\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def bracket_filter(sentence, mode='phonetic'):\n",
    "    new_sentence = str()\n",
    "\n",
    "    if mode == 'phonetic':\n",
    "        flag = False\n",
    "\n",
    "        for ch in sentence:\n",
    "            if ch == '(' and flag is False:\n",
    "                flag = True\n",
    "                continue\n",
    "            if ch == '(' and flag is True:\n",
    "                flag = False\n",
    "                continue\n",
    "            if ch != ')' and flag is False:\n",
    "                new_sentence += ch\n",
    "\n",
    "    elif mode == 'spelling':\n",
    "        flag = True\n",
    "\n",
    "        for ch in sentence:\n",
    "            if ch == '(':\n",
    "                continue\n",
    "            if ch == ')':\n",
    "                if flag is True:\n",
    "                    flag = False\n",
    "                    continue\n",
    "                else:\n",
    "                    flag = True\n",
    "                    continue\n",
    "            if ch != ')' and flag is True:\n",
    "                new_sentence += ch\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported mode : {0}\".format(mode))\n",
    "\n",
    "    return new_sentence\n",
    "\n",
    "\n",
    "def special_filter(sentence, mode='phonetic', replace=None):\n",
    "    SENTENCE_MARK = ['?', '!', '.']\n",
    "    NOISE = ['o', 'n', 'u', 'b', 'l']\n",
    "    EXCEPT = ['/', '+', '*', '-', '@', '$', '^', '&', '[', ']', '=', ':', ';', ',']\n",
    "\n",
    "    new_sentence = str()\n",
    "    for idx, ch in enumerate(sentence):\n",
    "        if ch not in SENTENCE_MARK:\n",
    "            if idx + 1 < len(sentence) and ch in NOISE and sentence[idx + 1] == '/':\n",
    "                continue\n",
    "\n",
    "        if ch == '#':\n",
    "            new_sentence += '샾'\n",
    "\n",
    "        elif ch == '%':\n",
    "            if mode == 'phonetic':\n",
    "                new_sentence += replace\n",
    "            elif mode == 'spelling':\n",
    "                new_sentence += '%'\n",
    "\n",
    "        elif ch not in EXCEPT:\n",
    "            new_sentence += ch\n",
    "\n",
    "    pattern = re.compile(r'\\s\\s+')\n",
    "    new_sentence = re.sub(pattern, ' ', new_sentence.strip())\n",
    "    return new_sentence\n",
    "\n",
    "\n",
    "def sentence_filter(raw_sentence, mode, replace=None):\n",
    "    return special_filter(bracket_filter(raw_sentence, mode), mode, replace)\n",
    "\n",
    "\n",
    "PERCENT_FILES = {\n",
    "    '087797': '퍼센트',\n",
    "    '215401': '퍼센트',\n",
    "    '284574': '퍼센트',\n",
    "    '397184': '퍼센트',\n",
    "    '501006': '프로',\n",
    "    '502173': '프로',\n",
    "    '542363': '프로',\n",
    "    '581483': '퍼센트'\n",
    "}\n",
    "\n",
    "\n",
    "def read_preprocess_text_file(file_path, mode):\n",
    "    with open(file_path, 'r', encoding='cp949') as f:\n",
    "        raw_sentence = f.read()\n",
    "        file_name = os.path.basename(file_path)\n",
    "        if file_name[12:18] in PERCENT_FILES.keys():\n",
    "            replace = PERCENT_FILES[file_name[12:18]]\n",
    "        else:\n",
    "            replace = None\n",
    "        return sentence_filter(raw_sentence, mode=mode, replace=replace)\n",
    "\n",
    "\n",
    "def preprocess(dataset_path, mode='phonetic'):\n",
    "    print('preprocess started..')\n",
    "\n",
    "    audio_paths = []\n",
    "    transcripts = []\n",
    "\n",
    "    with Parallel(n_jobs=cpu_count() - 1) as parallel:\n",
    "\n",
    "        for idx, subfolder in tqdm(list(enumerate(os.listdir(dataset_path))), desc=f'Preprocess text files on {dataset_path}'):\n",
    "            path = os.path.join(dataset_path, subfolder)\n",
    "\n",
    "            # list-up files\n",
    "            sub_file_list = [\n",
    "                os.path.join(path, file_name) for file_name in os.listdir(path) if file_name.endswith('.json')\n",
    "            ]\n",
    "            audio_sub_file_list = [\n",
    "                os.path.join(subfolder, file_name)\n",
    "                for file_name in os.listdir(path) if file_name.endswith('.json')\n",
    "            ]\n",
    "\n",
    "            # do parallel and get results\n",
    "            new_sentences = parallel(\n",
    "                delayed(read_preprocess_text_file)(p, mode) for p in sub_file_list\n",
    "            )\n",
    "\n",
    "            audio_paths.extend(audio_sub_file_list)\n",
    "            transcripts.extend(new_sentences)\n",
    "\n",
    "    return audio_paths, transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __오디오 파일과 텍스트 파일을 처리해줍니다.__\n",
    "> 오디오 파일을 벡터로 변환시키는 이유는 허깅페이스에 업로드하기 위함입니다. 허깅페이스 업로드를 하지 않을 시 text만 전처리하도록 수정을 권장드립니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE =16000  \n",
    "\n",
    "def data_process(wav: str, annotation:str,): \n",
    "    \"\"\"\n",
    "    loading paths into waveform and text.\n",
    "    Args\n",
    "        wav(str) : path of .wav or .mp3 file \n",
    "        annotation(str) : patho of annotation \n",
    "    Return\n",
    "        audio_arr (list) : list of numpy array containing wave form sampled in 16kHz \n",
    "        text_arr (list) : list of sentences.\n",
    "    \"\"\"\n",
    "    audio = whisper.load_audio(wav) #오디오파일을 벡터 값으로 불러옴 - sr: 16kHz\n",
    "\n",
    "    with open(annotation) as f: #Json 파일 가져옴 \n",
    "        data = json.load(f)       \n",
    "\n",
    "    audio_arr, text_arr = [], [] \n",
    "    for row in data['dialogs']: \n",
    "        start = int(row['startTime']) * SAMPLE_RATE  #발화자의 발화 시작 시간 \n",
    "        end = int(row['endTime']) * SAMPLE_RATE #발화 종료 시간 \n",
    "        audio_arr.append(audio[start:end]) #발화자의 시작-종료 시간만 가져옴 \n",
    "\n",
    "        sentence = sentence_filter(row['speakerText'], mode='spelling')\n",
    "        text_arr.append(sentence)\n",
    "    return audio_arr, text_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of files: 150\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008408_210918_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014091_210927_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_023474_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_022260_211010_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008953_210916_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007971_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014914_211001_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_021071_211006_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023518_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_023456_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014654_210928_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_021073_211006_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007837_210821_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_016754_210930_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007963_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007964_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008324_210917_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_029723_210920_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007969_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014105_210927_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007838_210821_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007967_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_023469_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007970_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014920_211001_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_013801_210917_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_014041_210927_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_096909_210918_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023519_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_015687_211003_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_023445_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_096911_210918_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_023457_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_096914_210918_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023495_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023505_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014637_211005_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007966_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_021066_211006_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007968_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014114_210927_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_014896_211001_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_016767_210930_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007962_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_020468_211008_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_030425_210922_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008406_210918_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008407_210918_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008952_210916_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_030421_210922_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023491_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023504_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014110_210927_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008518_210910_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_015524_211002_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014926_211001_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023521_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_019060_211028_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_013798_210917_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_015504_211002_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014939_211001_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014671_210928_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_008940_210916_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_007965_210909_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014279_210929_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_019453_211007_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_020986_211006_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_023459_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_014662_210928_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_030424_210922_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_013736_210917_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_07_023483_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_023492_211011_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_015512_211002_SN.wav\n",
      "pass /home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안/06_08_008170_210912_SN.wav\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/yerang/문서/ASR/python_speech_recognition/aihub/06.지하철,버스/02.지하철안\"\n",
    "wav_fns = glob.glob(osp.join(data_dir, '**', '*.wav'), recursive=True)\n",
    "print(f\" number of files: {len(wav_fns)}\") \n",
    "\n",
    "audios = [] \n",
    "texts = []\n",
    "for wav in wav_fns: \n",
    "    annotation = wav.replace(\".wav\", \".json\")\n",
    "    if not osp.isfile(annotation):\n",
    "        print(f\"pass {wav}\")\n",
    "        continue\n",
    "    #데이터 처리 \n",
    "    audio_arr, text_arr = data_process(wav, annotation)\n",
    "    for i, audio in enumerate(audio_arr):\n",
    "        audios.append(dict(\n",
    "                path=osp.basename(wav),\n",
    "                array=audio,\n",
    "                sampling_rate = 16000,\n",
    "            )) \n",
    "        texts.append(text_arr[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310\n",
      "1310\n"
     ]
    }
   ],
   "source": [
    "assert len(audios)==len(texts)\n",
    "print(len(audios))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __허깅페이스 데이터셋에 업로드(optional)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __datasets 라이브러리를 사용하여 커스텀 데이터셋을 업로드할 경우 허깅페이스 계정과 인증 토큰(WRITE 권한)이 필요합니다. 토큰은 설정에서 발급받을 수 있습니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "audio_dataset = Dataset.from_dict(dict(\n",
    "    audio = audios,\n",
    "    text = texts\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'text'],\n",
       "    num_rows: 1310\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __push_to_hub 함수를 이용하여 업로드할 수 있습니다. 레포지토리가 존재하지 않는다면 생성한 후 업로드합니다. private=True일 경우 본인의 액세스 토큰을 가지고 있는 사람만 접근가능합니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e79ba604e984c99a3c8d3a99d152e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0366488b98d84ab7a14d4da2b09269dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c246810484404d2abbc6e39138a44829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92912a77f57445c7a13ca31394f18fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3677ffd7404c03b03e5ba55633d9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/539 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/zzrng76/aihub-noise-dataset-subway/commit/7f274d7e5f5c883f7328d0538334115209bd79ea', commit_message='Upload dataset', commit_description='', oid='7f274d7e5f5c883f7328d0538334115209bd79ea', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repository 생성 & upload\n",
    "REPO_NAME = \"zzrng76/aihub-noise-dataset-subway\" #{사용자 이름}/{생성할 레포지토리 이름}\n",
    "AUTH_TOKEN = ... #개인 계정 토큰 입력\n",
    "audio_dataset.push_to_hub(REPO_NAME, token=AUTH_TOKEN, private=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
